# Monitoring Stack â€“ Prometheus & Grafana

> Phase 4 du plan de mise en Å“uvre : choix, architecture et prÃ©-conception des ressources pour l'observabilitÃ©.

---

## ğŸ¯ Objectifs

1. Collecter les mÃ©triques systÃ¨me et applicatives de toutes les VM dÃ©ployÃ©es par Terraform.
2. Visualiser en temps rÃ©el l'Ã©tat de la plateforme (dashboards Grafana).
3. Mettre en place des alertes (Alertmanager) qui dÃ©clenchent des notifications (e-mail / Teams / Slack).
4. S'intÃ©grer au pipeline CI/CD afin de valider le bon fonctionnement aprÃ¨s chaque dÃ©ploiement.

---

## ğŸ› ï¸ Choix des outils

| Composant | RÃ´le | Version cible |
|-----------|------|---------------|
| **Prometheus** | Scraping & stockage des mÃ©triques TS | 2.52.0 |
| **Node Exporter** | Exporter de mÃ©triques systÃ¨me (VM) | 1.7.0 |
| **Grafana** | Visualisation & alertes UI | 10.x |
| **Alertmanager** | Gestion des notifications d'alerte | v0.27 |

Pourquoi ce stack ?
* Cloud-agnostic, open-source, mature.
* Large Ã©cosystÃ¨me de dashboards prÃªts Ã  l'emploi.
* Facile Ã  dÃ©ployer (binaries ou containers).

---

## ğŸ—ï¸ Architecture cible (Azure)

```mermaid
flowchart TD
  subgraph RG[Resource Group "monitoring-rg"]
    VM[â›³ monitoring-vm (Ubuntu)]
    disk[(Managed Disk /data)]
    NSG[ğŸ”’ NSG monitoring-nsg]
  end
  VM -- port 9090 --> Internet
  VM -- port 3000 --> Internet
  VM -- scrape --> Nodes((App / DB / Other VMs))
```

1. **VM Linux (Standard_B2s)** hÃ©bergeant :
   * Prometheus (`/etc/prometheus`, donnÃ©es `/data/prometheus`)
   * Grafana (port 3000)
   * Alertmanager (port 9093)
2. **Managed disk** attachÃ© en `/data` pour persistance.
3. **NSG** autorisant :
   * TCP 9090 â†’ Prometheus UI
   * TCP 3000 â†’ Grafana UI
   * TCP 9093 â†’ Alertmanager (optionnel)
4. **DNS** : enregistrement `monitoring.<domain>` (non gÃ©rÃ© dans cette phase).

---

## ğŸ“¦ DÃ©ploiement â€“ Terraform

Un nouveau module `terraform/modules/monitoring` sera crÃ©Ã© :
* `main.tf` : VM, disque, NSG, IP publique.
* `variables.tf` : `prefix`, `location`, `vm_size`, etc.
* `outputs.tf` : IP publique, ports exposÃ©s.

Le root `terraform/main.tf` instanciera ce module quand `var.enable_monitoring` = `true`.

---

## ğŸš€ Configuration â€“ Ansible

Le rÃ´le `monitoring` (crÃ©Ã© en phase 2) sera enrichi :
* Installation binaries Prometheus, Node Exporter, Alertmanager.
* Services systemd.
* DÃ©ploiera des dashboards JSON dans Grafana via API.
* GÃ¨rera les alert rules (`*.yml`) placÃ©es dans `monitoring/alert_rules/`.

---

## ğŸ”” Alertes initiales

| Nom | Expression | Seuil | GravitÃ© |
|-----|------------|-------|---------|
| `HighCPU` | `avg by(instance)(rate(node_cpu_seconds_total{mode!="idle"}[5m])) > 0.8` | >80 % | warning |
| `InstanceDown` | `up == 0` | N/A | critical |

---

## ğŸ—ºï¸ Dashboards

Dashboards Grafana importÃ©s :
* **Node Exporter Full** (ID 1860).
* **Prometheus 2.0 Overview** (ID 3662).
* Dashboard custom Â« Application Â» (Ã  crÃ©er plus tard).

---

## â­ï¸ Prochaines Ã©tapes (Phase 4)

1. **ImplÃ©menter** le module Terraform `monitoring` + variables par dÃ©faut.
2. **Ã‰tendre** le rÃ´le Ansible `monitoring` : installation et configuration des services.
3. **Ajouter** les alert rules et dashboards dans `monitoring/`.
4. **Mettre Ã  jour** les workflows CI/CD pour :
   * VÃ©rifier que le port 9090 rÃ©pond aprÃ¨s dÃ©ploiement.
   * Exporter les artefacts dashboards comme snapshot GitHub.

---

> Une fois ces Ã©tapes terminÃ©es, la plateforme bÃ©nÃ©ficiera d'une observabilitÃ© de base prÃªte Ã  Ãªtre enrichie. 